{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate as ev # importing \n",
    "import numpy as np     \n",
    "from model_builder import * \n",
    "!pip install gdown  \n",
    "import gdown # package that downloads files from a shared google drive to local system\n",
    "#import nltk\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f64ab6",
   "metadata": {},
   "source": [
    "## Section 1 - Exercising all functionality with n=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf965d8",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left; color: black;\">Perplexity Of Held Out Set</h3>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cfeaa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note - calculating the perplexity of the entire data yields an undefined perplexity measure (extremely high as the probability the model assigns the data is extremely small)\n",
    "\n",
    "# calculates average sentence perplexity across data \n",
    "def average_perplexity(n:int, use_smoothing:bool, data:list):  \n",
    "    perplexities = []\n",
    "    for sentence in data:  \n",
    "        # calculating the perplexity of each sentence\n",
    "        perplexities.append(ev.calculate_perplexity_sentence(n=n, use_smoothing=use_smoothing, sentence=sentence, clean_sentence=True)) \n",
    "    return np.nanmean(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84478079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity with n=2 using good turing smoothing is <43006148.60803921>\n",
      "Perplexity with n=2 unsmoothed is <43006148.60803921>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_url = \"https://drive.google.com/uc?export=download&id=1QiTMvnjYu-e0BxkKOych9WhrV13x77fO\" \n",
    "\n",
    "\n",
    "output = 'test_data.txt' \n",
    "\n",
    "# Download the file\n",
    "#gdown.download(\"https://drive.google.com/uc?export=download&id=1QiTMvnjYu-e0BxkKOych9WhrV13x77fO\" , output, quiet=False)\n",
    "\n",
    "with open(output, 'r') as file: \n",
    "    test_data = file.read() \n",
    "\n",
    "# Note: We are calculating the average perplexity of the test data set sentence by sentence for 50 sentences in the test set. We observed that the perplexity of the entire test data is undefined as the probability the model assigns the test set data is effectively zero \n",
    "# There are also sentences in the test data set that have extremely high perplexities so \n",
    "\n",
    "sentences = test_data.split('+') \n",
    "sentences = sentences[:50]\n",
    "\n",
    "\n",
    "print(f\"Perplexity with n=2 using good turing smoothing is <{average_perplexity(n=2, use_smoothing=True, data=sentences)}>\")\n",
    "\n",
    "print(f\"Perplexity with n=2 unsmoothed is <{average_perplexity(n=2, use_smoothing=True, data=sentences)}>\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f51e7",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left; color: black;\">Unscrambling a sentence </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfcdf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: <N-gram with n = 2 i.e.  bigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  cat saw i a\n",
      "Unscrambled sentence:  i saw a cat\n",
      "Original Perplexity:  907891.0752602484\n",
      "Unscrambled Perplexity:  2561.874399156617\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .No smoothing used>\n",
      "Original Text:  cat saw i a\n",
      "Unscrambled sentence:  cat i saw a\n",
      "Original Perplexity:  Undefined\n",
      "Unscrambled Perplexity:  155795.6131688053\n"
     ]
    }
   ],
   "source": [
    "with open('eg_scrambled_sentence.txt', 'w') as file: \n",
    "    file.write(\"cat saw i a\") \n",
    "    \n",
    "ev.unscramble(n=2, use_smoothing=True, scrambled_file='eg_scrambled_sentence.txt')\n",
    "ev.unscramble(n=2, use_smoothing=False, scrambled_file='eg_scrambled_sentence.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a17c91",
   "metadata": {},
   "source": [
    "## Section 2 - Exercising all functionality with n=2 on new data source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773f62b",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left; color: black;\">Perplexity of new data</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60a44c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=146pd1hoMUdHjz-irf0yBy-YKuhg-FBHY\n",
      "To: C:\\Users\\rohit\\PycharmProjects\\CSDS497\\new_data.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2.21k/2.21k [00:00<00:00, 1.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity with n=2 using good turing smoothing is: <2442291.2992360266>\n",
      "Perplexity with n=2 without smoothing: <7702569.208915002>\n"
     ]
    }
   ],
   "source": [
    "# our new data\n",
    "output = 'new_data.txt'  \n",
    "\n",
    "# Download the file - can comment this out if the file has already been downloaded \n",
    "# This file is called new_data.txt and is available in the shared google drive linked in the README\n",
    "gdown.download(\"https://drive.google.com/uc?export=download&id=146pd1hoMUdHjz-irf0yBy-YKuhg-FBHY\" , output, quiet=False) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cleans text file at the specified path\n",
    "def preprocess_data(filepath:str)->list: \n",
    "    # Reading contents from file \n",
    "    with open(filepath, 'r') as file: \n",
    "        new_data = file.read() \n",
    "\n",
    "    # calling the clean_corpus function to clean(remove special characters and convert to lower case) and lemmatize string\n",
    "    cleaned_data = clean_corpus(new_data) \n",
    "    cleaned_data = cleaned_data.split('+') # get all the sentences in our novel corpus(each sentence ends with an '+' EOS character)\n",
    "    cleaned_data = [sentence for sentence in cleaned_data if sentence.strip()]\n",
    "\n",
    "    for i in range(len(cleaned_data)):\n",
    "        cleaned_data[i] = '+'+ cleaned_data[i] # adding a special EOS character that represents the end of one sentence and the start of another\n",
    "    return cleaned_data \n",
    "\n",
    "cleaned_data = preprocess_data('new_data.txt')  \n",
    "\n",
    "# Using a smoothed bigram model to get the average sentence perplexity in the test set\n",
    "print(f\"Perplexity with n=2 using good turing smoothing is: <{average_perplexity(n=2, use_smoothing=True, data=cleaned_data)}>\") \n",
    "\n",
    "# Using an unsmoothed bigram model to get the average sentence perplexity in the test \n",
    "print(f\"Perplexity with n=2 without smoothing: <{average_perplexity(n=2, use_smoothing=False, data=cleaned_data)}>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246135d",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left; color: black;\">Unscrambling a sentence </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8c0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: <N-gram with n = 2 i.e.  bigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  they ball red saw a\n",
      "Unscrambled sentence:  they saw a red ball\n",
      "Original Perplexity:  31022963.59629315\n",
      "Unscrambled Perplexity:  13131.422739635205\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .No smoothing used>\n",
      "Original Text:  they ball red saw a\n",
      "Unscrambled sentence:  red ball a they saw\n",
      "Original Perplexity:  Undefined\n",
      "Unscrambled Perplexity:  944134.4671214414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('new_data_scrambled.txt', 'w') as file: \n",
    "    file.write('they ball red saw a') \n",
    "    \n",
    "#using a smoothed bigram model to unscramble \n",
    "ev.unscramble(n=2, use_smoothing=True, scrambled_file='new_data_scrambled.txt') \n",
    "\n",
    "#using an unsmoothed bigram model to unscramble \n",
    "ev.unscramble(n=2, use_smoothing=False, scrambled_file='new_data_scrambled.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd260e2",
   "metadata": {},
   "source": [
    "## Section 3- Comparing performance of models for n=1,2,3 on the new data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461a540",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left; color: black;\">Perplexity of new data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d2efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity with n=1 using good turing smoothing is: <964.3445896021693>\n",
      "Perplexity with n=2 using good turing smoothing is: <2442291.2992360266>\n",
      "Perplexity with n=3 using good turing smoothing is: <3365598214995.135>\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# calling preprocess_data method defined before\n",
    "cleaned_data = preprocess_data('new_data.txt')\n",
    "\n",
    "# calculating average sentence perplexity(in new data set)\n",
    "print(f\"Perplexity with n=1 using good turing smoothing is: <{average_perplexity(n=1, use_smoothing=True, data=cleaned_data)}>\") \n",
    "print(f\"Perplexity with n=2 using good turing smoothing is: <{average_perplexity(n=2, use_smoothing=True, data=cleaned_data)}>\") \n",
    "print(f\"Perplexity with n=3 using good turing smoothing is: <{average_perplexity(n=3, use_smoothing =True, data=cleaned_data)}>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e6369",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left; color: black;\">Unscrambling a sentence using n-gram models where n=1,2,3</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc4d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: <N-gram with n = 1 i.e.  unigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  a is cat this\n",
      "Unscrambled sentence:  a is cat this\n",
      "Original Perplexity:  339.7988347502979\n",
      "Unscrambled Perplexity:  339.7988347502979\n",
      "\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  a is cat this\n",
      "Unscrambled sentence:  this is a cat\n",
      "Original Perplexity:  40812917.61629939\n",
      "Unscrambled Perplexity:  736.4214701181066\n",
      "\n",
      "Language Model: <N-gram with n = 3 i.e.  trigram .Uses Good-Turing Smoothing with a log-function>\n"
     ]
    }
   ],
   "source": [
    "# create a file with scrambled text \n",
    "\n",
    "# here we assume that all the words in the scrambled sentence are from our lexicon \n",
    "\n",
    "with open('scrambled_sentence.txt', 'w') as file: \n",
    "    file.write('a is cat this') \n",
    "\n",
    "# demonstrating the unscrambler using n=1,2,3 smoothed n grams \n",
    "ev.unscramble(n=1, use_smoothing=True,scrambled_file = 'scrambled_sentence.txt') \n",
    "print()  \n",
    "ev.unscramble(n=2, use_smoothing=True, scrambled_file='scrambled_sentence.txt')\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e795c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: <N-gram with n = 3 i.e.  trigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  a is cat this\n",
      "Unscrambled sentence:  cat is a this\n",
      "Original Perplexity:  4538365171.359575\n",
      "Unscrambled Perplexity:  83943.18060161584\n"
     ]
    }
   ],
   "source": [
    "ev.unscramble(n=3, use_smoothing=True, scrambled_file = 'scrambled_sentence.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1e6e5",
   "metadata": {},
   "source": [
    "## Section 4- Comparing performance of smoothed and unsmoothed models where n=2 on data drawn from lexicon and data necessarily drawn from lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b9f51",
   "metadata": {},
   "source": [
    "### Data drawn from lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50192d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: <N-gram with n = 2. No smoothing used>\n",
      "Perplexity = <Undefined>\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .No smoothing used>\n",
      "Original Text:  chair sat cat on the the\n",
      "Unscrambled sentence:  sat on the chair the cat\n",
      "Original Perplexity:  Undefined\n",
      "Unscrambled Perplexity:  950192.501162325\n",
      "Language Model: <N-gram with n = 2. Uses Good-Turing Smoothing with a log-function>\n",
      "Perplexity = <2589391.154690356>\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  chair sat cat on the the\n",
      "Unscrambled sentence:  sat on the chair the cat\n",
      "Original Perplexity:  4312485.81614361\n",
      "Unscrambled Perplexity:  5186.606104977492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a file containing text which is made of tokens present in our lexicon (but could include other tokens) \n",
    "\n",
    "with open('not_strictly_lexicon.txt', 'w') as file: \n",
    "    file.write('Susie played the guitar She did not see her mom') \n",
    "    \n",
    "with open('scrambled_text_bigram_demo.txt', 'w') as file: \n",
    "    file.write('chair sat cat on the the')\n",
    "\n",
    "# using an unsmoothed bigram model to get the perplexity of the text\n",
    "ev.calculate_perplexity(n=2, use_smoothing=False, test_data_file='not_strictly_lexicon.txt') \n",
    "\n",
    "# demonstrating the usncrambler for an unsmoothed bigram model  \n",
    "ev.unscramble(n=2, use_smoothing=False, scrambled_file='scrambled_text_bigram_demo.txt') \n",
    "\n",
    "# using a smoothed bigram model to get the perplexity of the text\n",
    "ev.calculate_perplexity(n=2, use_smoothing=True, test_data_file='not_strictly_lexicon.txt') \n",
    "\n",
    "#demonstrating the unscrambler for a smoothed bigram model \n",
    "ev.unscramble(n=2, use_smoothing=True, scrambled_file='scrambled_text_bigram_demo.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ff7e0",
   "metadata": {},
   "source": [
    "### Data necessarily drawn from lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a6f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: <N-gram with n = 2. No smoothing used>\n",
      "Perplexity = <Undefined>\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .No smoothing used>\n",
      "Original Text:  chair sat cat on the the\n",
      "Unscrambled sentence:  sat on the chair the cat\n",
      "Original Perplexity:  Undefined\n",
      "Unscrambled Perplexity:  950192.501162325\n",
      "Language Model: <N-gram with n = 2. Uses Good-Turing Smoothing with a log-function>\n",
      "Perplexity = <3346106.4254960623>\n",
      "Language Model: <N-gram with n = 2 i.e.  bigram .Uses Good-Turing Smoothing with a log-function>\n",
      "Original Text:  chair sat cat on the the\n",
      "Unscrambled sentence:  sat on the chair the cat\n",
      "Original Perplexity:  4312485.81614361\n",
      "Unscrambled Perplexity:  5186.606104977492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Creating a file containing text which is strictly made of tokens present in our lexicon \n",
    "\n",
    "with open('lexicon_only.txt', 'w') as file: \n",
    "    file.write('The cat sat on the chair.The man read the news on his phone.There was no music playing.')  \n",
    "    \n",
    "with open('scrambled_text_bigram_demo.txt', 'w') as file: \n",
    "    file.write('chair sat cat on the the')\n",
    "\n",
    "# using an unsmoothed bigram model to get the perplexity of the text made of tokens strictly from our lexicon \n",
    "ev.calculate_perplexity(n=2, use_smoothing=False, test_data_file='lexicon_only.txt') \n",
    "\n",
    "# demonstrating the usncrambler for an unsmoothed bigram model  \n",
    "ev.unscramble(n=2, use_smoothing=False, scrambled_file='scrambled_text_bigram_demo.txt') \n",
    "\n",
    "# using a smoothed bigram model to get the perplexity of the text made of tokens scrictly from our lexicon \n",
    "ev.calculate_perplexity(n=2, use_smoothing=True, test_data_file='lexicon_only.txt') \n",
    "\n",
    "#demonstrating the unscrambler for a smoothed bigram model \n",
    "ev.unscramble(n=2, use_smoothing=True, scrambled_file='scrambled_text_bigram_demo.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d64fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
